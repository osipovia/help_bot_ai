"""
–î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.

–†–µ–∞–ª–∏–∑—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ OpenRouter API —Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º KISS.
"""

import time
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from src.config.settings import logger


@dataclass
class LLMRequestMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω–æ–≥–æ LLM –∑–∞–ø—Ä–æ—Å–∞"""
    timestamp: str
    user_id: str
    model: str
    request_size_chars: int
    messages_count: int
    has_context: bool
    has_history: bool
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–≤–µ—Ç–∞
    response_time_ms: float
    success: bool
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    
    # –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    error_type: Optional[str] = None
    error_message: Optional[str] = None
    
    # –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞
    response_length_chars: int = 0
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        return asdict(self)


class LLMLogger:
    """–õ–æ–≥–≥–µ—Ä –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ LLM –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.log_full_content = False  # –î–ª—è production –ª—É—á—à–µ False (privacy)
        self.metrics_history: List[LLMRequestMetrics] = []
        self.max_history_size = 100  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø—Ä–æ—Å–æ–≤
        
        logger.info("üìä LLM Logger –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def start_request(self, user_id: str, model: str, messages: List[Dict], 
                     found_services: str = "", conversation_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """
        –ù–∞—á–∏–Ω–∞–µ—Ç –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            model: –ú–æ–¥–µ–ª—å LLM
            messages: –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
            found_services: –ù–∞–π–¥–µ–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            
        Returns:
            –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        request_context = {
            "start_time": time.time(),
            "user_id": user_id,
            "model": model,
            "messages_count": len(messages),
            "request_size_chars": sum(len(msg.get("content", "")) for msg in messages),
            "has_context": bool(found_services.strip()),
            "has_history": bool(conversation_history),
            "timestamp": datetime.now().isoformat()
        }
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self.log_full_content:
            logger.info(f"üì§ LLM Full Request –¥–ª—è {user_id}:")
            logger.info(f"  –ú–æ–¥–µ–ª—å: {model}")
            logger.info(f"  –°–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")
            logger.info(f"  –ö–æ–Ω—Ç–µ–∫—Å—Ç —É—Å–ª—É–≥: {len(found_services)} —Å–∏–º–≤–æ–ª–æ–≤")
            if conversation_history:
                logger.info(f"  –ò—Å—Ç–æ—Ä–∏—è: {len(conversation_history)} —Å–æ–æ–±—â–µ–Ω–∏–π")
            logger.info(f"  –ü–æ–ª–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {json.dumps(messages, ensure_ascii=False, indent=2)}")
        else:
            # –ö—Ä–∞—Ç–∫–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è production
            context_info = []
            if found_services.strip():
                context_info.append(f"—É—Å–ª—É–≥–∏:{len(found_services)}—á")
            if conversation_history:
                context_info.append(f"–∏—Å—Ç–æ—Ä–∏—è:{len(conversation_history)}–º")
            
            context_str = f" [{','.join(context_info)}]" if context_info else ""
            
            logger.info(
                f"üì§ LLM –∑–∞–ø—Ä–æ—Å {user_id}: {model}, "
                f"{len(messages)}—Å–æ–æ–±—â, {request_context['request_size_chars']}—Å–∏–º–≤{context_str}"
            )
        
        return request_context
    
    def log_success(self, request_context: Dict[str, Any], 
                   response_data: Dict[str, Any], assistant_message: str):
        """
        –õ–æ–≥–≥–∏—Ä—É–µ—Ç —É—Å–ø–µ—à–Ω—ã–π LLM –æ—Ç–≤–µ—Ç
        
        Args:
            request_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ start_request
            response_data: –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç API
            assistant_message: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        response_time_ms = (time.time() - request_context["start_time"]) * 1000
        usage = response_data.get("usage", {})
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = LLMRequestMetrics(
            timestamp=request_context["timestamp"],
            user_id=request_context["user_id"],
            model=request_context["model"],
            request_size_chars=request_context["request_size_chars"],
            messages_count=request_context["messages_count"],
            has_context=request_context["has_context"],
            has_history=request_context["has_history"],
            response_time_ms=response_time_ms,
            success=True,
            prompt_tokens=usage.get("prompt_tokens", 0),
            completion_tokens=usage.get("completion_tokens", 0),
            total_tokens=usage.get("total_tokens", 0),
            response_length_chars=len(assistant_message)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self._save_metrics(metrics)
        
        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—Ö–∞
        if self.log_full_content:
            logger.info(f"üì• LLM Full Response –¥–ª—è {metrics.user_id}:")
            logger.info(f"  –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time_ms:.1f}–º—Å")
            logger.info(f"  –¢–æ–∫–µ–Ω—ã: {metrics.prompt_tokens}+{metrics.completion_tokens}={metrics.total_tokens}")
            logger.info(f"  –û—Ç–≤–µ—Ç: {assistant_message}")
        else:
            # –ö—Ä–∞—Ç–∫–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            logger.info(
                f"üì• LLM —É—Å–ø–µ—Ö {metrics.user_id}: "
                f"{response_time_ms:.0f}–º—Å, {metrics.completion_tokens}—Ç–æ–∫–µ–Ω–æ–≤, "
                f"{metrics.response_length_chars}—Å–∏–º–≤–æ–ª–æ–≤"
            )
        
        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if response_time_ms > 10000:  # > 10 —Å–µ–∫—É–Ω–¥
            logger.warning(f"üêå –ú–µ–¥–ª–µ–Ω–Ω—ã–π LLM –æ—Ç–≤–µ—Ç: {response_time_ms:.1f}–º—Å –¥–ª—è {metrics.user_id}")
        
        if metrics.total_tokens > 3000:  # –ú–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤
            logger.warning(f"üî• –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤: {metrics.total_tokens} –¥–ª—è {metrics.user_id}")
    
    def log_error(self, request_context: Dict[str, Any], 
                 error_type: str, error_message: str):
        """
        –õ–æ–≥–≥–∏—Ä—É–µ—Ç –æ—à–∏–±–∫—É LLM –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            request_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ start_request
            error_type: –¢–∏–ø –æ—à–∏–±–∫–∏ (http_error, timeout, network, etc.)
            error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        """
        response_time_ms = (time.time() - request_context["start_time"]) * 1000
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –æ—à–∏–±–∫–∏
        metrics = LLMRequestMetrics(
            timestamp=request_context["timestamp"],
            user_id=request_context["user_id"],
            model=request_context["model"],
            request_size_chars=request_context["request_size_chars"],
            messages_count=request_context["messages_count"],
            has_context=request_context["has_context"],
            has_history=request_context["has_history"],
            response_time_ms=response_time_ms,
            success=False,
            prompt_tokens=0,
            completion_tokens=0,
            total_tokens=0,
            error_type=error_type,
            error_message=error_message[:200]  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self._save_metrics(metrics)
        
        # –õ–æ–≥–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
        logger.error(
            f"‚ùå LLM –æ—à–∏–±–∫–∞ {metrics.user_id}: {error_type} "
            f"—á–µ—Ä–µ–∑ {response_time_ms:.0f}–º—Å - {error_message[:100]}"
        )
    
    def _save_metrics(self, metrics: LLMRequestMetrics):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞"""
        self.metrics_history.append(metrics)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.metrics_history) > self.max_history_size:
            self.metrics_history = self.metrics_history[-self.max_history_size:]
    
    def get_statistics(self, hours: int = 24) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM –∑–∞ –ø–µ—Ä–∏–æ–¥
        
        Args:
            hours: –ü–µ—Ä–∏–æ–¥ –≤ —á–∞—Å–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        if not self.metrics_history:
            return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        cutoff_time = datetime.now().timestamp() - (hours * 3600)
        recent_metrics = [
            m for m in self.metrics_history 
            if datetime.fromisoformat(m.timestamp).timestamp() > cutoff_time
        ]
        
        if not recent_metrics:
            return {"error": f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours} —á–∞—Å–æ–≤"}
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_requests = len(recent_metrics)
        successful_requests = sum(1 for m in recent_metrics if m.success)
        failed_requests = total_requests - successful_requests
        
        success_rate = (successful_requests / total_requests) * 100 if total_requests > 0 else 0
        
        # –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        successful_metrics = [m for m in recent_metrics if m.success]
        if successful_metrics:
            avg_response_time = sum(m.response_time_ms for m in successful_metrics) / len(successful_metrics)
            avg_tokens = sum(m.total_tokens for m in successful_metrics) / len(successful_metrics)
            total_tokens_used = sum(m.total_tokens for m in successful_metrics)
        else:
            avg_response_time = avg_tokens = total_tokens_used = 0
        
        # –ü–æ–¥—Å—á–µ—Ç –æ—à–∏–±–æ–∫ –ø–æ —Ç–∏–ø–∞–º
        error_types = {}
        for m in recent_metrics:
            if not m.success and m.error_type:
                error_types[m.error_type] = error_types.get(m.error_type, 0) + 1
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
        unique_users = len(set(m.user_id for m in recent_metrics))
        
        stats = {
            "period_hours": hours,
            "total_requests": total_requests,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "success_rate_percent": round(success_rate, 1),
            "unique_users": unique_users,
            "avg_response_time_ms": round(avg_response_time, 1) if avg_response_time else 0,
            "avg_tokens_per_request": round(avg_tokens, 1) if avg_tokens else 0,
            "total_tokens_used": total_tokens_used,
            "error_breakdown": error_types,
            "requests_with_context": sum(1 for m in recent_metrics if m.has_context),
            "requests_with_history": sum(1 for m in recent_metrics if m.has_history)
        }
        
        logger.info(f"üìä LLM —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ {hours}—á: {stats}")
        return stats
    
    def enable_full_logging(self, enabled: bool = True):
        """–í–∫–ª—é—á–∞–µ—Ç/–≤—ã–∫–ª—é—á–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"""
        self.log_full_content = enabled
        status = "–≤–∫–ª—é—á–µ–Ω–æ" if enabled else "–≤—ã–∫–ª—é—á–µ–Ω–æ"
        logger.info(f"üîç –ü–æ–ª–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ LLM: {status}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ LLM –∫–ª–∏–µ–Ω—Ç–µ
llm_logger = LLMLogger() 